{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blaze SQL Query Engine - Python Integration\n",
    "\n",
    "This notebook demonstrates how to use the Blaze SQL query engine with Python,\n",
    "including PyArrow integration, Pandas/Polars conversion, and visualization.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "```bash\n",
    "pip install pyarrow pandas polars matplotlib\n",
    "pip install blaze-sql  # When Python bindings are available\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the necessary libraries and create a connection to Blaze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.ipc as ipc\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# When Blaze Python bindings are available:\n",
    "# from blaze import Connection\n",
    "\n",
    "print(f\"PyArrow version: {pa.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"Polars version: {pl.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Sample Data\n",
    "\n",
    "Let's create some sample data using PyArrow and register it with Blaze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample sales data\n",
    "np.random.seed(42)\n",
    "n_rows = 1000\n",
    "\n",
    "sales_data = pa.table({\n",
    "    'order_id': pa.array(range(1, n_rows + 1)),\n",
    "    'product': pa.array(np.random.choice(['Widget', 'Gadget', 'Gizmo', 'Thing'], n_rows)),\n",
    "    'quantity': pa.array(np.random.randint(1, 20, n_rows)),\n",
    "    'price': pa.array(np.random.uniform(10, 500, n_rows).round(2)),\n",
    "    'region': pa.array(np.random.choice(['North', 'South', 'East', 'West'], n_rows)),\n",
    "    'date': pa.array(pd.date_range('2024-01-01', periods=n_rows, freq='H'))\n",
    "})\n",
    "\n",
    "print(f\"Created table with {sales_data.num_rows} rows\")\n",
    "print(f\"Schema: {sales_data.schema}\")\n",
    "sales_data.slice(0, 5).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create customer data\n",
    "customers_data = pa.table({\n",
    "    'customer_id': pa.array(range(1, 101)),\n",
    "    'name': pa.array([f'Customer_{i}' for i in range(1, 101)]),\n",
    "    'region': pa.array(np.random.choice(['North', 'South', 'East', 'West'], 100)),\n",
    "    'tier': pa.array(np.random.choice(['Bronze', 'Silver', 'Gold', 'Platinum'], 100))\n",
    "})\n",
    "\n",
    "print(f\"Created customers table with {customers_data.num_rows} rows\")\n",
    "customers_data.slice(0, 5).to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulated Blaze Queries\n",
    "\n",
    "The following cells show example queries that would work with Blaze.\n",
    "For now, we'll simulate the results using Pandas/Polars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Pandas for simulation\n",
    "sales_df = sales_data.to_pandas()\n",
    "sales_df['revenue'] = sales_df['quantity'] * sales_df['price']\n",
    "\n",
    "# Simulating: SELECT region, SUM(quantity * price) as revenue FROM sales GROUP BY region\n",
    "region_revenue = sales_df.groupby('region')['revenue'].sum().reset_index()\n",
    "print(\"Regional Revenue Summary:\")\n",
    "print(region_revenue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Polars for fast analytics\n",
    "sales_pl = pl.from_arrow(sales_data)\n",
    "\n",
    "# Simulating: SELECT product, AVG(price), COUNT(*) FROM sales GROUP BY product ORDER BY COUNT(*) DESC\n",
    "product_stats = (\n",
    "    sales_pl\n",
    "    .group_by('product')\n",
    "    .agg([\n",
    "        pl.col('price').mean().alias('avg_price'),\n",
    "        pl.len().alias('order_count'),\n",
    "        (pl.col('quantity') * pl.col('price')).sum().alias('total_revenue')\n",
    "    ])\n",
    "    .sort('order_count', descending=True)\n",
    ")\n",
    "\n",
    "print(\"Product Statistics:\")\n",
    "print(product_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart of regional revenue\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Regional revenue bar chart\n",
    "ax1 = axes[0]\n",
    "colors = ['#2ecc71', '#3498db', '#9b59b6', '#e74c3c']\n",
    "ax1.bar(region_revenue['region'], region_revenue['revenue'], color=colors)\n",
    "ax1.set_xlabel('Region')\n",
    "ax1.set_ylabel('Revenue ($)')\n",
    "ax1.set_title('Revenue by Region')\n",
    "ax1.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x:,.0f}'))\n",
    "\n",
    "# Product distribution pie chart\n",
    "ax2 = axes[1]\n",
    "product_counts = sales_df['product'].value_counts()\n",
    "ax2.pie(product_counts.values, labels=product_counts.index, autopct='%1.1f%%', colors=colors)\n",
    "ax2.set_title('Order Distribution by Product')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series analysis\n",
    "sales_df['date'] = pd.to_datetime(sales_df['date'])\n",
    "daily_revenue = sales_df.set_index('date').resample('D')['revenue'].sum()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "ax.plot(daily_revenue.index, daily_revenue.values, color='#3498db', linewidth=2)\n",
    "ax.fill_between(daily_revenue.index, daily_revenue.values, alpha=0.3, color='#3498db')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Daily Revenue ($)')\n",
    "ax.set_title('Daily Revenue Trend')\n",
    "ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x:,.0f}'))\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Arrow IPC Format\n",
    "\n",
    "Blaze returns results in Arrow IPC format for efficient data transfer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serialize table to Arrow IPC (simulating Blaze output)\n",
    "sink = pa.BufferOutputStream()\n",
    "with ipc.new_stream(sink, sales_data.schema) as writer:\n",
    "    writer.write_table(sales_data)\n",
    "arrow_buffer = sink.getvalue()\n",
    "\n",
    "print(f\"Arrow IPC buffer size: {len(arrow_buffer):,} bytes\")\n",
    "\n",
    "# Read back from Arrow IPC (simulating reading Blaze results)\n",
    "reader = ipc.open_stream(arrow_buffer)\n",
    "result_table = reader.read_all()\n",
    "print(f\"Read back {result_table.num_rows} rows\")\n",
    "result_table.slice(0, 3).to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Window Functions Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulating window functions with Polars\n",
    "# This would be: SELECT *, ROW_NUMBER() OVER (PARTITION BY region ORDER BY revenue DESC) as rank\n",
    "\n",
    "ranked_sales = (\n",
    "    sales_pl\n",
    "    .with_columns([\n",
    "        (pl.col('quantity') * pl.col('price')).alias('revenue')\n",
    "    ])\n",
    "    .with_columns([\n",
    "        pl.col('revenue')\n",
    "          .rank(method='ordinal', descending=True)\n",
    "          .over('region')\n",
    "          .alias('region_rank')\n",
    "    ])\n",
    "    .filter(pl.col('region_rank') <= 3)\n",
    "    .sort(['region', 'region_rank'])\n",
    ")\n",
    "\n",
    "print(\"Top 3 orders by revenue in each region:\")\n",
    "print(ranked_sales.select(['order_id', 'product', 'region', 'revenue', 'region_rank']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration with Blaze (When Available)\n",
    "\n",
    "Once Blaze Python bindings are installed, you can use them like this:\n",
    "\n",
    "```python\n",
    "from blaze import Connection\n",
    "\n",
    "# Create connection\n",
    "conn = Connection.in_memory()\n",
    "\n",
    "# Register Arrow table\n",
    "conn.register_arrow('sales', sales_data)\n",
    "conn.register_arrow('customers', customers_data)\n",
    "\n",
    "# Execute query and get Arrow result\n",
    "result = conn.query_arrow('''\n",
    "    SELECT \n",
    "        region,\n",
    "        COUNT(*) as order_count,\n",
    "        SUM(quantity * price) as total_revenue,\n",
    "        AVG(price) as avg_price\n",
    "    FROM sales\n",
    "    GROUP BY region\n",
    "    ORDER BY total_revenue DESC\n",
    "''')\n",
    "\n",
    "# Convert to Pandas\n",
    "df = result.to_pandas()\n",
    "print(df)\n",
    "\n",
    "# Or convert to Polars\n",
    "pl_df = pl.from_arrow(result)\n",
    "print(pl_df)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complex Query Examples\n",
    "\n",
    "Here are some complex SQL queries that Blaze supports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example queries (as strings for reference)\n",
    "queries = {\n",
    "    \"CTE with aggregation\": \"\"\"\n",
    "        WITH daily_totals AS (\n",
    "            SELECT \n",
    "                DATE(date) as order_date,\n",
    "                region,\n",
    "                SUM(quantity * price) as revenue\n",
    "            FROM sales\n",
    "            GROUP BY DATE(date), region\n",
    "        )\n",
    "        SELECT \n",
    "            order_date,\n",
    "            region,\n",
    "            revenue,\n",
    "            SUM(revenue) OVER (\n",
    "                PARTITION BY region \n",
    "                ORDER BY order_date \n",
    "                ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n",
    "            ) as running_total\n",
    "        FROM daily_totals\n",
    "        ORDER BY region, order_date\n",
    "    \"\"\",\n",
    "    \n",
    "    \"Subquery in WHERE\": \"\"\"\n",
    "        SELECT *\n",
    "        FROM sales\n",
    "        WHERE price > (\n",
    "            SELECT AVG(price) * 1.5\n",
    "            FROM sales\n",
    "        )\n",
    "    \"\"\",\n",
    "    \n",
    "    \"CASE with window function\": \"\"\"\n",
    "        SELECT \n",
    "            product,\n",
    "            price,\n",
    "            CASE \n",
    "                WHEN price >= (SELECT PERCENTILE_CONT(0.9) WITHIN GROUP (ORDER BY price) FROM sales) THEN 'Premium'\n",
    "                WHEN price >= (SELECT PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY price) FROM sales) THEN 'Standard'\n",
    "                ELSE 'Budget'\n",
    "            END as price_tier,\n",
    "            RANK() OVER (PARTITION BY product ORDER BY price DESC) as price_rank\n",
    "        FROM sales\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "for name, query in queries.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Query: {name}\")\n",
    "    print('='*60)\n",
    "    print(query.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Create larger dataset for benchmarking\n",
    "large_n = 100_000\n",
    "large_data = pa.table({\n",
    "    'id': pa.array(range(large_n)),\n",
    "    'value': pa.array(np.random.uniform(0, 1000, large_n)),\n",
    "    'category': pa.array(np.random.choice(['A', 'B', 'C', 'D'], large_n))\n",
    "})\n",
    "\n",
    "# Pandas timing\n",
    "large_df = large_data.to_pandas()\n",
    "start = time.time()\n",
    "result_pd = large_df.groupby('category')['value'].agg(['sum', 'mean', 'count'])\n",
    "pandas_time = time.time() - start\n",
    "\n",
    "# Polars timing\n",
    "large_pl = pl.from_arrow(large_data)\n",
    "start = time.time()\n",
    "result_pl = large_pl.group_by('category').agg([\n",
    "    pl.col('value').sum(),\n",
    "    pl.col('value').mean(),\n",
    "    pl.len()\n",
    "])\n",
    "polars_time = time.time() - start\n",
    "\n",
    "print(f\"Dataset size: {large_n:,} rows\")\n",
    "print(f\"Pandas aggregation: {pandas_time*1000:.2f}ms\")\n",
    "print(f\"Polars aggregation: {polars_time*1000:.2f}ms\")\n",
    "print(f\"Polars speedup: {pandas_time/polars_time:.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Results\n",
    "\n",
    "Blaze supports COPY TO syntax for exporting results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example COPY TO queries (for reference)\n",
    "export_examples = [\n",
    "    \"COPY (SELECT * FROM sales WHERE region = 'North') TO 'north_sales.parquet'\",\n",
    "    \"COPY (SELECT * FROM sales) TO 'all_sales.csv' WITH (FORMAT CSV, HEADER true)\",\n",
    "    \"COPY (SELECT * FROM sales) TO 'sales.json' WITH (FORMAT JSON)\"\n",
    "]\n",
    "\n",
    "print(\"Example COPY TO statements:\")\n",
    "for example in export_examples:\n",
    "    print(f\"  {example}\")\n",
    "\n",
    "# Using PyArrow directly to save\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# Save as Parquet\n",
    "# pq.write_table(sales_data, 'sales.parquet')\n",
    "print(\"\\nTo save with PyArrow:\")\n",
    "print(\"  pq.write_table(result, 'output.parquet')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **PyArrow Integration** - Creating and manipulating Arrow tables\n",
    "2. **Pandas Conversion** - Converting between Arrow and Pandas DataFrames\n",
    "3. **Polars Conversion** - Using Polars for fast analytics\n",
    "4. **Visualization** - Creating charts with matplotlib\n",
    "5. **Arrow IPC** - Working with Arrow's binary format\n",
    "6. **Window Functions** - Ranking and running totals\n",
    "7. **Complex Queries** - CTEs, subqueries, and CASE expressions\n",
    "8. **Performance** - Comparing execution times\n",
    "\n",
    "When Blaze Python bindings are available, you can use them seamlessly with\n",
    "the Python data science ecosystem."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
